# First Research Paper - Experiments

Experiments conducted for the research paper presented at IEEE 7th International Conference on Big Data and Artificial Intelligence (BDAI2024) held at North China University of Technology, Beijing, China, on July 5-7, 2024.

<p align="center">
  <img src="https://github.com/user-attachments/assets/8a9cf2fd-54a7-4a52-a8e2-70f9c994cd1b" alt="Certificate" width="400"/>
  <img src="https://github.com/user-attachments/assets/185e91db-8268-4246-a7ef-efab480df9fc" alt="Conference" width="400" height="300"/>
  
</p>

## Title:
Overcoming the Challenges of Large Language Models: Introducing a Novel Proposition for Synthetic Data Validation

## Authors:
- Urvashi Bhargava
- Y. Teresha
- Nishank Koul
- Chandrashekhar Pomu Chavan

### Abstract
This repository contains experimental code and data related to the challenges addressed in our research paper on Large Language Models (LLMs). The paper explores issues such as data scarcity, synthetic data validation, domain-specific understanding, model hallucinations, and the reversal curse phenomenon.

For detailed findings and methodologies, please refer to our full research paper.

### Key Points
- Advancements in LLMs: The evolution and capabilities of current LLMs including SORA, Gemini, and Microsoft Copilot.
- Challenges Addressed: Highlights major challenges like data scarcity, synthetic data validation, domain-specific understanding, model hallucinations, and the reversal curse.
- Proposed Solutions: Introduces innovative approaches such as bidirectional knowledge graphs and truth-table propositions for synthetic data validation.

### Conclusion
This repository serves as a reference for researchers and professionals interested in the challenges and solutions for LLMs.
